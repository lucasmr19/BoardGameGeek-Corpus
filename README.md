# ðŸ§© BoardGameGeek Corpus

**BoardGameGeek Corpus** is a Python project for building and analyzing an annotated textual corpus of **board game reviews**.  
It focuses on sentiment analysis, linguistic annotation, and lexicon-based modeling from user-generated content gathered from [BoardGameGeek](https://boardgamegeek.com).

## ðŸš€ Overview

This project automates the **collection, processing, and annotation** of board game reviews to create a reusable **linguistic corpus** for NLP and sentiment classification tasks.

- **Corpus construction** from multiple sources (crawler/API).
- **Text preprocessing**: cleaning, normalization, tokenization, lemmatization, POS tagging.
- **Linguistic annotation**: sentiment, negations, intensifiers, domain terms, hedges.
- **Balanced datasets** for supervised sentiment classification.
- **Vectorization and modeling**: TF-IDF, opinion features, and classifiers.

For detailed descriptions of modules, see the respective [`README.md`](./src/bgg_corpus/README.md) files.

## ðŸ“ Project Structure

```
BoardGameGeek-Corpus/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ api/                  # API metadata JSONs
â”‚   â”œâ”€â”€ crawler/              # Crawler reviews JSONs and stats
â”‚   â”œâ”€â”€ lexicons/             # Sentiment, hedge, domain lexicons
â”‚   â”œâ”€â”€ processed/            # Balanced corpora, datasets, vectors, models
â”‚   â”‚   â”œâ”€â”€ balance_reports/
â”‚   â”‚   â”œâ”€â”€ corpora/
â”‚   â”‚   â”‚   â”œâ”€â”€ bgg_corpus.json
â”‚   â”‚   â”‚   â””â”€â”€ statistics/    # Corpus statistics and figures
â”‚   â”‚   â”‚       â”œâ”€â”€ corpus_statistics_report.txt
â”‚   â”‚   â”‚       â””â”€â”€ figures/
â”‚   â”‚   â”‚           â”œâ”€â”€ lexical_dispersion.png
â”‚   â”‚   â”‚           â”œâ”€â”€ word_frequency_distribution.png
â”‚   â”‚   â”‚           â””â”€â”€ word_length_distribution.png
â”‚   â”‚   â”œâ”€â”€ datasets/         # Train/val/test splits
â”‚   â”‚   â”œâ”€â”€ models/           # Trained models & summaries
â”‚   â”‚   â””â”€â”€ vectors/          # TF-IDF and opinion feature matrices
â”‚   â””â”€â”€ raw/                  # Original dump CSV from BGG page: https://boardgamegeek.com/data_dumps/bg_ranks
â”œâ”€â”€ docs/                     # Diagrams and figures
â”œâ”€â”€ notebooks/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ bgg_corpus/           # Core Python package
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ preprocessing/    # Cleaning, tokenization, spaCy analysis
â”‚       â”œâ”€â”€ features/         # Lexicons, vectorization
â”‚       â”œâ”€â”€ models/           # Corpus and document classes
â”‚       â”œâ”€â”€ utilities/        # Helpers, corpus builder
â”‚       â”œâ”€â”€ balancing/        # Oversampling/undersampling/augmentation
â”‚       â”œâ”€â”€ storage/          # MongoDB storage
â”‚       â””â”€â”€ downloaders/      # Crawler/API downloaders
â”‚   â””â”€â”€ scripts/              # Executable scripts post-corpus creation
â””â”€â”€ tests/
```

## âš™ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/lucasmr19/BoardGameGeek-Corpus.git
cd BoardGameGeek-Corpus
pip install -r requirements.txt
```

## ðŸ›  Scripts Overview

All executable scripts are supposed to run post-corpus creation, see here [scripts README](./src/scripts/README.md)

| Script                 | Description                                                                            |
| ---------------------- | -------------------------------------------------------------------------------------- |
| `pln_p2_7462_02_e1.py` | Extract linguistic features (sentiment, negations, intensifiers, hedges, domain terms) |
| `pln_p2_7462_02_e2.py` | Vectorization (TF-IDF n-grams + opinion features)                                      |
| `pln_p2_7462_02_e3.py` | Dataset creation (train/val/test splits)                                               |
| `pln_p2_7462_02_e4.py` | Classification model training (NB, SVM, RF, XGBoost)                                   |
| `pln_p2_7462_02_e5.py` | Model evaluation and technical report generation                                       |

## ðŸ§  Key Components

- **Corpus Construction:** [`corpus_builder.py`](./src/bgg_corpus/utilities/corpus_builder.py) â€“ handles aggregation of raw data into structured corpus objects.
- **Preprocessing:** [`processing_utils.py`](./src/bgg_corpus/utilities/processing_utils.py) â€“ text cleaning, normalization, tokenization, and lemmatization.
- **Corpus Objects:** [`CorpusDocument`](./src/bgg_corpus/models/corpus_document.py) â€“ core object representing a single review with annotations.
- **Feature Extraction:** [`linguistic_extractor.py`](./src/bgg_corpus/features/linguistic_extractor.py) â€“ extracts sentiment, lexical, and syntactic features.
- **Storage:** [`mongodb_storage.py`](./src/bgg_corpus/storage/mongodb_storage.py) â€“ optional persistence layer for storing/retrieving corpora in MongoDB.
- **Scripts:** Executables for feature extraction, vectorization, dataset creation, modeling, and evaluation.

> Each subpackage contains a `README.md` explaining its purpose, usage, and examples.

## ðŸ“Œ Project Goals

- Build a **domain-specific sentiment corpus** from BoardGameGeek reviews.
- Extract and annotate **linguistic and lexical features** for NLP tasks.
- Provide **structured datasets** for supervised sentiment classification.
- Enable **scalable and extensible analysis** for research or downstream applications.

## âš¡ Usage Notes

1. **Corpus creation** must be completed before running any script in `src/scripts/`.
2. **Scripts are independent** but rely on the preprocessed corpus JSON in `data/processed/corpora/bgg_corpus.json`.
3. Each script can accept optional parameters (paths, feature selection, splits, etc.). See individual examples in the [scripts README](./src/scripts/README.md).
4. Generated outputs (features, vectors, models, evaluation reports) are stored in the corresponding `data/processed/` subdirectories.

## License

This project is licensed under the [MIT License](LICENSE).
